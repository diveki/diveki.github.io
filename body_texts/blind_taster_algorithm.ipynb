{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms blind tasting wines (Soon be finished)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this study we present a simple application of Natural Language Processing to classifying grape types based on semi-professional text based description of a glass of wine. We build a classifier model with pipelines and test it through two different datasets. A part of one of the datasets was involved through the building of the concept while the other is a completely out of sample data source. We present classification results of 4 different grape types with an accuracy above 85% which is in our view quite remarkable concerning the simplicity of the model.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note: This is purely driven by sel-interest. None of the mentioned entities gave financial nor other type of support. Feel free to copy and distribute this work or give remarks or suggestions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wine is one of the most popular alcohols that is being produced. Its production, selling and understanding has several thousands of years of expertise. A big industry has developed around producing the wine but also around describing it. The latter is very important since wine comes in different colour, taste, smell etc. It is important to describe these features of a bottle to customers because almost all of us enjoy different aspects of a glass of wine. The people who describe the wine are called wine experts or sommeliers [[1](#ch7)].\n",
    "\n",
    "One has to be gifted with good genetics to be able to sense and identify numerous different smells and tastes and have enough lexical knowledge to map these features to his database of wine features. This way they can tell only from sampling a glass of wine what grape was used to make it, in which country was it made, what year and maybe some more. This is an amazing skill to have, but it requires years of practice (hopefully without getting drunk). There are schools, like the [Wine and Spirit Education Trust](https://www.wsetglobal.com/) [[2](#ch7)] where you can practice these skills and learn a framework to do blind tasting. They have their own terminology to describe certain wine features like: full-budied, oaky, dry, grassy etc. (see [[3](#ch7)] for a more complete list). \n",
    "\n",
    "Would it be possible to create an algorithm that can identify the grape, the country or the year (vintage) of a wine based on professional description of wines? We think it would be possible, but it is certainly not an easy task and has many conditions to perform it. The very first issue is to find a reliable, complete and professional description of ten thousands of wines (or even more). The second issue is to create a natural language processing (NLP) model that is capable of extracting the relevent information from the descriptions and put them into an input format that a machine can handle and understand. The final issue is to find a classifier that can read the input and based on a set of optimizable parameters it can correctly tell us the target feature (in this study it will be the grape type) of the corresponding wine description. \n",
    "\n",
    "In a previous study, called [Become a sommelier](https://diveki.github.io/projects/wine/wine.html) [[4](#ch7)], we explored the issue of collecting the data. We wrote a web scraping algorithm that collects wine descriptions from various online wine selling websites (please read that study for more details). This database contains roughly 2000 samples. These descriptions are more in a customer friendly style, rarely very detailed, in all together we could call them semi-professional descriptions, but written by experts. Later in our research we came accross a [Kaggle](https://www.kaggle.com/) [Wine Reviews](https://www.kaggle.com/zynicide/wine-reviews) [[5](#ch7)] by *zackthoutt*. He collected a similar database of wine descriptions from another source as we did and his database contains more than 100 thousand samples. This size of database starts to be in the usable range.\n",
    "\n",
    "In another previous study, called [Application of TfIdf-vectorizer on wine data](https://diveki.github.io/projects/wine/tfidf.html) [[6](#ch7)] we established the concept of our model that extracts information from the wine description and turns it into a vectorized bag-of-words model. We used our own data set (and not the Kaggle one) to build up all the aspects of our model, that we will present here too, but for more details read the mentioned study. To make sure that our model do not get biased during the building process, we divided it into a train and a test set and we use the same concept here too. Basically we neglected any knowledge from the test set during the building process.\n",
    "\n",
    "In this study we will combine the created NLP model with a classifier and test the model performance in different scenarios. We will show classification results on both databases separately and also show an example where the Kaggle database trains the constructed model and we test it on our database. We present hyperparameter optimization and kfold verification of the results too. \n",
    "\n",
    "This study will step through the following topics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Loading data](#ch1)\n",
    "2. [Model definition](#ch2)\n",
    " \n",
    "   2.1. [Stopwords](#ch2.1)\n",
    "\n",
    "   2.2. [POS tagging and Lemmatizing](#ch2.2)\n",
    "   \n",
    "   2.3. [Label encoding](#ch2.3)\n",
    "   \n",
    "   2.4. [Splitting data into train and test sets](#ch2.4)\n",
    "   \n",
    "   2.5. [Defining selectors](#ch2.5)\n",
    "   \n",
    "   2.6. [Defining data pre-processors](#ch2.6)\n",
    "   \n",
    "   2.7. [Defining classiffiers](#ch2.7)\n",
    "   \n",
    "3. [Train and test the model](#ch3)\n",
    "\n",
    "   3.1. [Analysis of train predictions](#ch3.1)\n",
    "   \n",
    "   3.2. [Analysis of test predictions](#ch3.2)\n",
    "   \n",
    "   3.3. [Testing with different classifiers](#ch3.3)\n",
    "\n",
    "   3.4. [Hyperparameter tuning](#ch3.4)\n",
    "   \n",
    "   3.5. [Kfold verification](#ch3.5)\n",
    "   \n",
    "4. [Classification of data from Kaggle](#ch4)\n",
    "\n",
    "   4.1. [Data formatting](#ch4.1)\n",
    "   \n",
    "   4.2. [Classification](#ch4.2)\n",
    "   \n",
    "5. [Cross-data validation of the model](#ch5)\n",
    "6. [Conclusion](#ch6)\n",
    "7. [References](#ch7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch1\"></a>\n",
    "# 1. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading all the required packages and data to solve the above described task. Most of the details about these steps are described in [Become a sommelier](https://diveki.github.io/projects/wine/wine.html) and [Application of Tfidf-vectorizer on wine data](https://diveki.github.io/projects/wine/tfidf.html). \n",
    "\n",
    "We start by loading *pandas, numpy, re, scikit-learn* and *nltk* packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# sklearn packages\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# nltk packages\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the wine data set that we scraped online. For the details about this data set see the Appendix of [Become a sommelier](https://diveki.github.io/projects/wine/wine.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abv</th>\n",
       "      <th>colour</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>grape_variety</th>\n",
       "      <th>name</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.5</td>\n",
       "      <td>red</td>\n",
       "      <td>USA</td>\n",
       "      <td>this wine has concentrated depth and purity of...</td>\n",
       "      <td>pinot noir</td>\n",
       "      <td>A to Z Pinot Noir 2014</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.5</td>\n",
       "      <td>red</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>a delicate, floral wine with soft cherry and s...</td>\n",
       "      <td>pinot noir</td>\n",
       "      <td>Alamos Seleccion Pinot Noir 2016</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.5</td>\n",
       "      <td>red</td>\n",
       "      <td>Italy</td>\n",
       "      <td>a medium-bodied wine, with aromas and flavours...</td>\n",
       "      <td>pinot noir</td>\n",
       "      <td>Alois Lageder Alto Adige Pinot Noir 2014</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.5</td>\n",
       "      <td>white</td>\n",
       "      <td>Italy</td>\n",
       "      <td>very fresh aromas and flavours of gooseberry a...</td>\n",
       "      <td>sauvignon blanc</td>\n",
       "      <td>Alois Lageder Terlaner Sauvignon Blanc 2016</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.5</td>\n",
       "      <td>red</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>this wine has concentrated aromas and flavours...</td>\n",
       "      <td>cabernet sauvignon</td>\n",
       "      <td>Argento Cabernet Sauvignon 2014</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    abv colour    country                                        description  \\\n",
       "0  13.5    red        USA  this wine has concentrated depth and purity of...   \n",
       "1  13.5    red  Argentina  a delicate, floral wine with soft cherry and s...   \n",
       "2  12.5    red      Italy  a medium-bodied wine, with aromas and flavours...   \n",
       "3  13.5  white      Italy  very fresh aromas and flavours of gooseberry a...   \n",
       "4  13.5    red  Argentina  this wine has concentrated aromas and flavours...   \n",
       "\n",
       "        grape_variety                                         name    Body  \n",
       "0          pinot noir                       A to Z Pinot Noir 2014   light  \n",
       "1          pinot noir             Alamos Seleccion Pinot Noir 2016  medium  \n",
       "2          pinot noir     Alois Lageder Alto Adige Pinot Noir 2014  medium  \n",
       "3     sauvignon blanc  Alois Lageder Terlaner Sauvignon Blanc 2016  medium  \n",
       "4  cabernet sauvignon              Argento Cabernet Sauvignon 2014    full  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../DataBase/5_grape_db.xlsx'\n",
    "\n",
    "a0 = pd.read_excel(filename)\n",
    "a0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set contains all kinds of information about 5 grape types. We will use only 4 of the grape types, since the 5th does not have many samples. These 4 types are: *pinot noir, syrah* (red wines) and *chardonnay, sauvignon blanc* (white wines). By setting a limit to the minimum sample size we filter the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = a0['grape_variety']\n",
    "limit = 40\n",
    "## removing varieties that have only one member in the database\n",
    "counts = nltk.Counter(result)\n",
    "varieties = [key for key in counts if counts[key] > limit]\n",
    "data_input = a0[a0['grape_variety'].isin(varieties)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>abv</th>\n",
       "      <th>colour</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>grape_variety</th>\n",
       "      <th>name</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>red</td>\n",
       "      <td>USA</td>\n",
       "      <td>this wine has concentrated depth and purity of...</td>\n",
       "      <td>pinot noir</td>\n",
       "      <td>A to Z Pinot Noir 2014</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>red</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>a delicate, floral wine with soft cherry and s...</td>\n",
       "      <td>pinot noir</td>\n",
       "      <td>Alamos Seleccion Pinot Noir 2016</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>red</td>\n",
       "      <td>Italy</td>\n",
       "      <td>a medium-bodied wine, with aromas and flavours...</td>\n",
       "      <td>pinot noir</td>\n",
       "      <td>Alois Lageder Alto Adige Pinot Noir 2014</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>white</td>\n",
       "      <td>Italy</td>\n",
       "      <td>very fresh aromas and flavours of gooseberry a...</td>\n",
       "      <td>sauvignon blanc</td>\n",
       "      <td>Alois Lageder Terlaner Sauvignon Blanc 2016</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>white</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>this lightly oaked wine offers aromas of ripe ...</td>\n",
       "      <td>chardonnay</td>\n",
       "      <td>Argento Chardonnay 2015</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   abv colour    country  \\\n",
       "0      0  13.5    red        USA   \n",
       "1      1  13.5    red  Argentina   \n",
       "2      2  12.5    red      Italy   \n",
       "3      3  13.5  white      Italy   \n",
       "4      5  13.0  white  Argentina   \n",
       "\n",
       "                                         description    grape_variety  \\\n",
       "0  this wine has concentrated depth and purity of...       pinot noir   \n",
       "1  a delicate, floral wine with soft cherry and s...       pinot noir   \n",
       "2  a medium-bodied wine, with aromas and flavours...       pinot noir   \n",
       "3  very fresh aromas and flavours of gooseberry a...  sauvignon blanc   \n",
       "4  this lightly oaked wine offers aromas of ripe ...       chardonnay   \n",
       "\n",
       "                                          name    Body  \n",
       "0                       A to Z Pinot Noir 2014   light  \n",
       "1             Alamos Seleccion Pinot Noir 2016  medium  \n",
       "2     Alois Lageder Alto Adige Pinot Noir 2014  medium  \n",
       "3  Alois Lageder Terlaner Sauvignon Blanc 2016  medium  \n",
       "4                      Argento Chardonnay 2015  medium  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this dataframe we will only use some of the features. The columns description and colour are the most important ones, but in the our first implementation we will add the Body feature as an input too. Let us see an example what does the code face in the descripiton column and extract reliable information in order to be able to classify grape types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a delicate, floral wine with soft cherry and strawberry flavours. medium-bodied, fresh and bright, with smooth supple tannins and a savoury, spicy chocolate finish. an 8-hour-long maceration period, followed by cold-settling racked fresh from the press. lees stirring to increase texture. 35-day-long fermentation period at an average temperature of 9-12c.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input.loc[1, 'description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch2\"></a>\n",
    "# 2. Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we showed in [Application of Tfidf-vectorizer on wine data](https://diveki.github.io/projects/wine/tfidf.html) in order to classify the grape types correctly, the processed input data for one grape should not correlate with other grape types. The applied model has to minimize this correlation. We did not perform an exact optimization process but rather added newer features to the model step-by-step and investigated what happens with the correlation. All the features presented here are the result of the mentioned study, so for details please go and read it. Some of the steps presented below are not discussed in that study, therefore we will elaborate them more. \n",
    "\n",
    "Our model will be a very simple vectorized 1-gramm bag-of-words model. We will rely on term frequency - inverse document frequency (tf-idf) vectorization and some additional noise filters and word processors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch2.1\"></a>\n",
    "## 2.1. Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, there are words in the description column that are certainly not adding any information about the grape type, like *with, and, by* etc. We can collect a list of these kind of words and call them stopwords. These will be filtered out from the text and not taken into account in the classification process. We will exploit the *nltk* package's stopwords and extend it with some words and punctuations defined by us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining stopwords: using the one that comes with nltk + appending it with words seen from the above evaluation\n",
    "stop_words = stopwords.words('english')\n",
    "stop_append = ['.', ',', '`', '\"', \"'\", '!', ';', 'wine', 'fruit', '%', 'flavour', 'aromas', 'palate']\n",
    "stop_words1 = frozenset(stop_words + stop_append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch2.2\"></a>\n",
    "## 2.2. POS tagging and Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text we want to analyse may contain the same word in different forms. A very simple example would be *cherry* and *cherries* the singular and plural version of the same word. Another example could be *good* and *better*. In their original form, these words are treated as separete ones by the code. To bring them to their common form we apply [lemmatization](https://en.wikipedia.org/wiki/Lemmatisation) [[7](#ch7)]. This is a very difficult task since it requires correct identification of the word (noun, verb etc.) type in the context. The latter is position tagging or POS tagging. We use *nltk*'s pos tagger, but as any other tagger this is not perfect neither. \n",
    "\n",
    "The most information of a wine description is carried in its nouns and adjectives. Verbs and adverbs are rather common words to most of the wines. In our model we apply a filter that leaves nouns and adjectives in the text and removes anything else. \n",
    "\n",
    "The POS tagging, lemmatizing and type selecting is carried out by the *LemmaTokenizer* class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of word types (nouns and adjectives) to leave in the text\n",
    "defTags = ['NN', 'NNS', 'NNP', 'NNPS', 'JJ', 'JJS', 'JJR']#, 'RB', 'RBS', 'RBR', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "# functions to determine the type of a word\n",
    "def is_noun(tag):\n",
    "    return tag in ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "\n",
    "\n",
    "def is_verb(tag):\n",
    "    return tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "\n",
    "def is_adverb(tag):\n",
    "    return tag in ['RB', 'RBR', 'RBS']\n",
    "\n",
    "\n",
    "def is_adjective(tag):\n",
    "    return tag in ['JJ', 'JJR', 'JJS']\n",
    "\n",
    "# transform tag forms\n",
    "def penn_to_wn(tag):\n",
    "    if is_adjective(tag):\n",
    "        return nltk.stem.wordnet.wordnet.ADJ\n",
    "    elif is_noun(tag):\n",
    "        return nltk.stem.wordnet.wordnet.NOUN\n",
    "    elif is_adverb(tag):\n",
    "        return nltk.stem.wordnet.wordnet.ADV\n",
    "    elif is_verb(tag):\n",
    "        return nltk.stem.wordnet.wordnet.VERB\n",
    "    return nltk.stem.wordnet.wordnet.NOUN\n",
    "    \n",
    "# lemmatizer + tokenizer (+ stemming) class\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        # we define (but not use) a stemming method, uncomment the last line in __call__ to get stemming tooo\n",
    "        self.stemmer = nltk.stem.SnowballStemmer('english') \n",
    "    def __call__(self, doc):\n",
    "        # pattern for numbers | words of length=2 | punctuations | words of length=1\n",
    "        pattern = re.compile(r'[0-9]+|\\b[\\w]{2,2}\\b|[%.,_`!\"&?\\')({~@;:#}+-]+|\\b[\\w]{1,1}\\b')\n",
    "        # tokenize document\n",
    "        doc_tok = word_tokenize(doc)\n",
    "        #filter out patterns from words\n",
    "        doc_tok = [pattern.sub('', x) for x in doc_tok]\n",
    "        # get rid of anything with length=1\n",
    "        doc_tok = [x for x in doc_tok if len(x) > 1]\n",
    "        # position tagging\n",
    "        doc_tagged = nltk.pos_tag(doc_tok)\n",
    "        # selecting nouns and adjectives\n",
    "        doc_tagged = [(t[0], t[1]) for t in doc_tagged if t[1] in defTags]\n",
    "        # preparing lemmatization\n",
    "        doc = [(t[0], penn_to_wn(t[1])) for t in doc_tagged]\n",
    "        # lemmatization\n",
    "        doc = [self.wnl.lemmatize(t[0], t[1]) for t in doc]\n",
    "        # uncomment if you want stemming as well\n",
    "        #doc = [self.stemmer.stem(x) for x in doc]\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch2.3\"></a>\n",
    "## 2.3. Label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, we are mainly interested in classification by using text based description, from the database we can see that there are other, possible helpful features of the wine, that can help to classify. Such features are *body* and *colour*. Both of them are used by sommeliers to describe a wine. Colour can be easily observed while body is reflecting in a way the acidity of a wine. \n",
    "\n",
    "These columns in the database are defined in text format, so we have to turn them into numbers so that the computer can understand them. Both of these features have discreate value, so we could just easily attach a number to them like: *red=1*, *rose=2*, *white=3*. This is called [label encoding](https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621) [[8](#ch7)]. This would not be a disastrous approach, but the classifier might think there there is a trend like tendency between these categories (because of the increase in numbers), which is obviously false. Instead, sticking to the case of colours, we create three more columns (there are three colours), each representing one colour. Each column can take two values, 0 (if the wine does not have that feature) and 1 (if the wine has that feature). We do this for both the body and colour columns with the *pandas* get_dummies method.\n",
    "\n",
    "The following cell prints an example of the modified data set that contains the encoded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>abv</th>\n",
       "      <th>colour</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>grape_variety</th>\n",
       "      <th>name</th>\n",
       "      <th>Body</th>\n",
       "      <th>dry</th>\n",
       "      <th>full</th>\n",
       "      <th>light</th>\n",
       "      <th>medium</th>\n",
       "      <th>red</th>\n",
       "      <th>rose</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>red</td>\n",
       "      <td>USA</td>\n",
       "      <td>this wine has concentrated depth and purity of...</td>\n",
       "      <td>pinot noir</td>\n",
       "      <td>A to Z Pinot Noir 2014</td>\n",
       "      <td>light</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>red</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>a delicate, floral wine with soft cherry and s...</td>\n",
       "      <td>pinot noir</td>\n",
       "      <td>Alamos Seleccion Pinot Noir 2016</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>red</td>\n",
       "      <td>Italy</td>\n",
       "      <td>a medium-bodied wine, with aromas and flavours...</td>\n",
       "      <td>pinot noir</td>\n",
       "      <td>Alois Lageder Alto Adige Pinot Noir 2014</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>white</td>\n",
       "      <td>Italy</td>\n",
       "      <td>very fresh aromas and flavours of gooseberry a...</td>\n",
       "      <td>sauvignon blanc</td>\n",
       "      <td>Alois Lageder Terlaner Sauvignon Blanc 2016</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>white</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>this lightly oaked wine offers aromas of ripe ...</td>\n",
       "      <td>chardonnay</td>\n",
       "      <td>Argento Chardonnay 2015</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   abv colour    country  \\\n",
       "0      0  13.5    red        USA   \n",
       "1      1  13.5    red  Argentina   \n",
       "2      2  12.5    red      Italy   \n",
       "3      3  13.5  white      Italy   \n",
       "4      5  13.0  white  Argentina   \n",
       "\n",
       "                                         description    grape_variety  \\\n",
       "0  this wine has concentrated depth and purity of...       pinot noir   \n",
       "1  a delicate, floral wine with soft cherry and s...       pinot noir   \n",
       "2  a medium-bodied wine, with aromas and flavours...       pinot noir   \n",
       "3  very fresh aromas and flavours of gooseberry a...  sauvignon blanc   \n",
       "4  this lightly oaked wine offers aromas of ripe ...       chardonnay   \n",
       "\n",
       "                                          name    Body  dry  full  light  \\\n",
       "0                       A to Z Pinot Noir 2014   light    0     0      1   \n",
       "1             Alamos Seleccion Pinot Noir 2016  medium    0     0      0   \n",
       "2     Alois Lageder Alto Adige Pinot Noir 2014  medium    0     0      0   \n",
       "3  Alois Lageder Terlaner Sauvignon Blanc 2016  medium    0     0      0   \n",
       "4                      Argento Chardonnay 2015  medium    0     0      0   \n",
       "\n",
       "   medium  red  rose  white  \n",
       "0       0    1     0      0  \n",
       "1       1    1     0      0  \n",
       "2       1    1     0      0  \n",
       "3       1    0     0      1  \n",
       "4       1    0     0      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_dummies = pd.get_dummies(data_input['Body'])       # label encoding the Body column\n",
    "colour_dummies = pd.get_dummies(data_input['colour'])   # label encoding the colour column\n",
    "# adding the body labels to the original dataset\n",
    "data_input = data_input.merge(body_dummies, left_index=True, right_index=True)\n",
    "# adding the colour labels to the original dataset\n",
    "data_input = data_input.merge(colour_dummies, left_index=True, right_index=True)\n",
    "data_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch2.4\"></a>\n",
    "## 2.4. Splitting data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have already mentioned the analysis in [4,6](#ch7) were performed on a preselected train dataset from the whole database. We will use exactly the same train dataset to train our model. This is easy to do by setting the *random_state* argument to the same value as it was in those studies. Also, we only select the columns of description, labelled colours and labelled bodies. The *train_test_split* function will create train and test features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "combined_features = ['Body', 'description', 'full', 'light', 'medium', 'dry', 'red', 'rose', 'white']\n",
    "target = 'grape_variety'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_input[combined_features], data_input[target], \n",
    "                                                    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>description</th>\n",
       "      <th>full</th>\n",
       "      <th>light</th>\n",
       "      <th>medium</th>\n",
       "      <th>dry</th>\n",
       "      <th>red</th>\n",
       "      <th>rose</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>medium</td>\n",
       "      <td>as seen on tv.the belen estate in chile 's cas...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>dry</td>\n",
       "      <td>this classic displays elements of gooseberry ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>dry</td>\n",
       "      <td>' quest to create an australian rival to the t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>full</td>\n",
       "      <td>are dedicated to showcasing the wide range of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>dry</td>\n",
       "      <td>made from a of the best grapes grown throughou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Body                                        description  full  light  \\\n",
       "229  medium  as seen on tv.the belen estate in chile 's cas...     0      0   \n",
       "257     dry  this classic displays elements of gooseberry ,...     0      0   \n",
       "260     dry  ' quest to create an australian rival to the t...     0      0   \n",
       "210    full  are dedicated to showcasing the wide range of ...     1      0   \n",
       "193     dry  made from a of the best grapes grown throughou...     0      0   \n",
       "\n",
       "     medium  dry  red  rose  white  \n",
       "229       1    0    1     0      0  \n",
       "257       0    1    0     0      1  \n",
       "260       0    1    0     0      1  \n",
       "210       0    0    1     0      0  \n",
       "193       0    1    0     0      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229         pinot noir\n",
       "257    sauvignon blanc\n",
       "260         chardonnay\n",
       "210              syrah\n",
       "193    sauvignon blanc\n",
       "Name: grape_variety, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch2.5\"></a>\n",
    "## 2.5. Defining selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build up a [pipeline](https://medium.com/@yanhann10/a-brief-view-of-machine-learning-pipeline-in-python-5f50b941fca8) for this study. In a pipeline we chain together all kind of actions on the data into one stable flow. For example it combines data transformers (numerical normaliser) with data estimators (Naive Bayes classifier).\n",
    "\n",
    "The input data has both text based and numerical features. They cannot be processed together by the classifier unless they are transformed into the same format, in this case numerical format. We aim to construct a pipeline that takes care of all these issues. \n",
    "\n",
    "We define two classes where one of them will select the text based column from the input, the other will select the numerical input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None, *parg, **kwarg):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # returns the input as a string\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # returns the input as a dataframe\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch2.6\"></a>\n",
    "## 2.6. Defining data pre-processors and pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, text based data cannot be used by the classifier. Therefore, we create a vectorizer that takes a string input and turns it into a vector of numbers. \n",
    "\n",
    "We will use the [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) with 1-grams of words, the predifined stopwords and LemmaTokenizer as helping tools. Tf-idf applies the bag-of-words concept, which creates a vocabulary (list of all the terms from the string) and maps a value to them. In the case of tf-idf this value is roughly the product of the term frequency (the number of times a term occured within the document string) and the inverse document frequency (the inverse of the the number of documents that this term is present). Basically, the first term emphasizes the terms that are frequent in one document while weighs down the terms that are frequent over several documents. The reason for the latter is that if a word is used in many documents it is unlikely that it has characteristic meaning to one topic. For more on this read the relevant sections in [Application of Tfidf-vectorizer on wine data](https://diveki.github.io/projects/wine/tfidf.html).\n",
    "\n",
    "Let us define the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tdidf = TfidfVectorizer(ngram_range=(1,1), stop_words=stop_words, analyzer='word', \n",
    "                                               norm='l2', tokenizer=LemmaTokenizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us combine the text vectorizer with the text selector into one pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Pipeline([\n",
    "                ('selector', TextSelector(key='description')),\n",
    "                ('vectorizer', vec_tdidf)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in the previous sell let us put the numeric selectors into pipelines too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines of body features\n",
    "full = Pipeline([\n",
    "                ('selector', NumberSelector(key='full')),\n",
    "                ])\n",
    "medium = Pipeline([\n",
    "                ('selector', NumberSelector(key='medium')),\n",
    "                ])\n",
    "light = Pipeline([\n",
    "                ('selector', NumberSelector(key='light')),\n",
    "                ])\n",
    "dry = Pipeline([\n",
    "                ('selector', NumberSelector(key='dry')),\n",
    "                ])\n",
    "\n",
    "#pipelines of colour features\n",
    "red = Pipeline([\n",
    "                ('selector', NumberSelector(key='red')),\n",
    "                ])\n",
    "rose = Pipeline([\n",
    "                ('selector', NumberSelector(key='rose')),\n",
    "                ])\n",
    "white = Pipeline([\n",
    "                ('selector', NumberSelector(key='white')),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us combine all these pipelines. Note, that to combine different features one has to use the [FeatureUnion](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html) class. Now we have all methods of transformation and pre-processing put into one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = FeatureUnion([('full', full),\n",
    "                      ('medium', medium),\n",
    "                      ('light', light),\n",
    "                      ('dry', dry),\n",
    "                      ('description', text),\n",
    "                      ('red', red),\n",
    "                      ('rose', rose),\n",
    "                      ('white', white)\n",
    "                      ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch2.7\"></a>\n",
    "## 2.7. Defining classiffiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step in our pipeline is to define a classifier. Our first choice of classifier is the [Random Forest](https://en.wikipedia.org/wiki/Random_forest). It is an ensemble classifier of decision trees and it tends to be more accurate than a single decision tree classifier. It is very versatile in application and fit to determine which features are giving the most contribution to good prediction (although we will not use this feature here). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us put this classifier in the pipeline to combine it with the feature union and then we are ready to go and do blind tasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('feats', feats),\n",
    "                 ('clf',clf)\n",
    "                 ])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch3\"></a>\n",
    "# 3. Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feats', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('full', Pipeline(steps=[('selector', NumberSelector(key='full'))])), ('medium', Pipeline(steps=[('selector', NumberSelector(key='medium'))])), ('light', Pipeline(steps=[('selector', NumberSelector(key='light'))])), ('dry', Pipeline(st...stimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch3.1\"></a>\n",
    "## 3.1. Analysis of train predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       1.00      1.00      1.00        58\n",
      "     pinot noir       1.00      1.00      1.00        40\n",
      "sauvignon blanc       1.00      1.00      1.00        55\n",
      "          syrah       1.00      1.00      1.00        27\n",
      "\n",
      "    avg / total       1.00      1.00      1.00       180\n",
      "\n",
      "[[58  0  0  0]\n",
      " [ 0 40  0  0]\n",
      " [ 0  0 55  0]\n",
      " [ 0  0  0 27]]\n",
      "Counter({'chardonnay': 58, 'sauvignon blanc': 55, 'pinot noir': 40, 'syrah': 27})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "#train stats\n",
    "preds = pipe.predict(X_train)\n",
    "print(metrics.accuracy_score(y_train, preds))\n",
    "print(metrics.classification_report(y_train, preds))\n",
    "print(metrics.confusion_matrix(y_train, preds))\n",
    "print(nltk.Counter(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch3.2\"></a>\n",
    "## 3.2. Analysis of test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7444444444444445\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.71      0.97      0.82        33\n",
      "     pinot noir       0.68      0.89      0.77        19\n",
      "sauvignon blanc       0.83      0.48      0.61        21\n",
      "          syrah       1.00      0.47      0.64        17\n",
      "\n",
      "    avg / total       0.79      0.74      0.73        90\n",
      "\n",
      "[[32  0  1  0]\n",
      " [ 2 17  0  0]\n",
      " [11  0 10  0]\n",
      " [ 0  8  1  8]]\n",
      "Counter({'chardonnay': 33, 'sauvignon blanc': 21, 'pinot noir': 19, 'syrah': 17})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "# test stats\n",
    "preds = pipe.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, preds))\n",
    "print(metrics.classification_report(y_test, preds))\n",
    "print(metrics.confusion_matrix(y_test, preds))\n",
    "print(nltk.Counter(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch3.3\"></a>\n",
    "## 3.3. Testing with different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4\"></a>\n",
    "## 3.4. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.5\"></a>\n",
    "## 3.5. Kfold verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956521739130435\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.71      0.97      0.82        31\n",
      "     pinot noir       0.62      0.50      0.56        20\n",
      "sauvignon blanc       0.94      0.58      0.71        26\n",
      "          syrah       0.50      0.60      0.55        15\n",
      "\n",
      "    avg / total       0.72      0.70      0.69        92\n",
      "\n",
      "[[30  0  1  0]\n",
      " [ 1 10  0  9]\n",
      " [11  0 15  0]\n",
      " [ 0  6  0  9]]\n",
      "Counter({'chardonnay': 31, 'sauvignon blanc': 26, 'pinot noir': 20, 'syrah': 15})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7888888888888889\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.81      0.73      0.77        30\n",
      "     pinot noir       0.77      0.85      0.81        20\n",
      "sauvignon blanc       0.73      0.88      0.80        25\n",
      "          syrah       0.91      0.67      0.77        15\n",
      "\n",
      "    avg / total       0.80      0.79      0.79        90\n",
      "\n",
      "[[22  0  8  0]\n",
      " [ 2 17  0  1]\n",
      " [ 3  0 22  0]\n",
      " [ 0  5  0 10]]\n",
      "Counter({'chardonnay': 30, 'sauvignon blanc': 25, 'pinot noir': 20, 'syrah': 15})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7613636363636364\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.72      0.87      0.79        30\n",
      "     pinot noir       0.75      0.95      0.84        19\n",
      "sauvignon blanc       0.79      0.60      0.68        25\n",
      "          syrah       0.89      0.57      0.70        14\n",
      "\n",
      "    avg / total       0.77      0.76      0.75        88\n",
      "\n",
      "[[26  0  4  0]\n",
      " [ 0 18  0  1]\n",
      " [10  0 15  0]\n",
      " [ 0  6  0  8]]\n",
      "Counter({'chardonnay': 30, 'sauvignon blanc': 25, 'pinot noir': 19, 'syrah': 14})\n",
      "Mean: 0.7486348997218562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "### stratified training\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "sc_mean=[]\n",
    "for train, test in skf.split(data_input[combined_features], data_input[target]):\n",
    "    pipe.fit(data_input.loc[train,combined_features], data_input.loc[train, target])\n",
    "    preds = pipe.predict(data_input.loc[test,combined_features])\n",
    "    sc_mean.append(metrics.accuracy_score(data_input.loc[test, target], preds))\n",
    "    \n",
    "    print(metrics.accuracy_score(data_input.loc[test, target], preds))\n",
    "    print(metrics.classification_report(data_input.loc[test, target], preds))\n",
    "    print(metrics.confusion_matrix(data_input.loc[test, target], preds))\n",
    "    print(nltk.Counter(data_input.loc[test, target]))\n",
    "print('Mean: %s' % str(sum(sc_mean)/len(sc_mean)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch4\"></a>\n",
    "# 4. Classification of data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>grape_variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>white blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>portuguese red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>pinot gris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>riesling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>pinot noir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description   grape_variety\n",
       "0  Aromas include tropical fruit, broom, brimston...     white blend\n",
       "1  This is ripe and fruity, a wine that is smooth...  portuguese red\n",
       "2  Tart and snappy, the flavors of lime flesh and...      pinot gris\n",
       "3  Pineapple rind, lemon pith and orange blossom ...        riesling\n",
       "4  Much like the regular bottling from 2012, this...      pinot noir"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../DataBase/winemag-data-130k-v2.csv'\n",
    "\n",
    "kaggle = pd.read_csv(filename, usecols=['description', 'grape_variety'])\n",
    "kaggle['grape_variety'] = kaggle['grape_variety'].str.lower()\n",
    "kaggle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch4.1\"></a>\n",
    "## 4.1. Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiraz_filter(ss):\n",
    "    if ss == 'shiraz':\n",
    "        return 'syrah'\n",
    "    else:\n",
    "        return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle['grape_variety'] = kaggle.apply(lambda row: shiraz_filter(row['grape_variety']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_input = kaggle[kaggle['grape_variety'].isin(varieties)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pinot noir', 'chardonnay', 'sauvignon blanc', 'syrah'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(kaggle_input.grape_variety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34943, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_dict = {'pinot noir': 'red', 'syrah': 'red', 'chardonnay': 'white', 'sauvignon blanc': 'white'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_input['colour'] = kaggle_input.apply(lambda row: colour_dict[row['grape_variety']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "combined_features = ['description']\n",
    "target = 'grape_variety'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(kaggle_input[combined_features], kaggle_input[target], \n",
    "                                                    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch4.2\"></a>\n",
    "## 4.2. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Pipeline([\n",
    "                ('selector', TextSelector(key='description')),\n",
    "                ('vectorizer', TfidfVectorizer(ngram_range=(1,1), stop_words=stop_words, analyzer='word', \n",
    "                                               norm='l2', tokenizer=LemmaTokenizer()))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('text', Pipeline(memory=None,\n",
       "     steps=[('selector', TextSelector(key='description')), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_featur...stimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('text', text),\n",
    "                 ('clf',RandomForestClassifier(random_state=42))\n",
    "                 ])\n",
    "    \n",
    "pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8415712799167534\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.81      0.95      0.87      3822\n",
      "     pinot noir       0.84      0.94      0.89      4378\n",
      "sauvignon blanc       0.90      0.59      0.71      1635\n",
      "          syrah       0.92      0.60      0.73      1697\n",
      "\n",
      "    avg / total       0.85      0.84      0.83     11532\n",
      "\n",
      "[[3620  109   89    4]\n",
      " [ 184 4100   11   83]\n",
      " [ 620   49  964    2]\n",
      " [  64  603    9 1021]]\n",
      "Counter({'pinot noir': 4378, 'chardonnay': 3822, 'syrah': 1697, 'sauvignon blanc': 1635})\n"
     ]
    }
   ],
   "source": [
    "# test stats\n",
    "preds = pipe.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, preds))\n",
    "print(metrics.classification_report(y_test, preds))\n",
    "print(metrics.confusion_matrix(y_test, preds))\n",
    "print(nltk.Counter(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845467032967033\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.81      0.94      0.87      3914\n",
      "     pinot noir       0.85      0.94      0.90      4421\n",
      "sauvignon blanc       0.89      0.58      0.70      1655\n",
      "          syrah       0.91      0.62      0.73      1658\n",
      "\n",
      "    avg / total       0.85      0.85      0.84     11648\n",
      "\n",
      "[[3689  109  112    4]\n",
      " [ 148 4175    6   92]\n",
      " [ 646   43  964    2]\n",
      " [  57  577    4 1020]]\n",
      "Counter({'pinot noir': 4421, 'chardonnay': 3914, 'syrah': 1658, 'sauvignon blanc': 1655})\n",
      "0.8390281593406593\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.80      0.95      0.87      3914\n",
      "     pinot noir       0.85      0.93      0.89      4421\n",
      "sauvignon blanc       0.89      0.56      0.68      1655\n",
      "          syrah       0.91      0.62      0.74      1658\n",
      "\n",
      "    avg / total       0.85      0.84      0.83     11648\n",
      "\n",
      "[[3723   90   95    6]\n",
      " [ 212 4094   19   96]\n",
      " [ 686   44  921    4]\n",
      " [  55  563    5 1035]]\n",
      "Counter({'pinot noir': 4421, 'chardonnay': 3914, 'syrah': 1658, 'sauvignon blanc': 1655})\n",
      "0.8443375976646347\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.80      0.96      0.87      3914\n",
      "     pinot noir       0.87      0.92      0.89      4421\n",
      "sauvignon blanc       0.87      0.58      0.69      1654\n",
      "          syrah       0.89      0.63      0.74      1658\n",
      "\n",
      "    avg / total       0.85      0.84      0.84     11647\n",
      "\n",
      "[[3749   54  109    2]\n",
      " [ 199 4080   25  117]\n",
      " [ 649   43  955    7]\n",
      " [  70  527   11 1050]]\n",
      "Counter({'pinot noir': 4421, 'chardonnay': 3914, 'syrah': 1658, 'sauvignon blanc': 1654})\n",
      "Mean: 0.842944263324109\n"
     ]
    }
   ],
   "source": [
    "### stratified training\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "sc_mean=[]\n",
    "for train, test in skf.split(kaggle_input[combined_features], kaggle_input[target]):\n",
    "    pipe.fit(kaggle_input.loc[train,combined_features], kaggle_input.loc[train, target])\n",
    "    preds = pipe.predict(kaggle_input.loc[test,combined_features])\n",
    "    sc_mean.append(metrics.accuracy_score(kaggle_input.loc[test, target], preds))\n",
    "    \n",
    "    print(metrics.accuracy_score(kaggle_input.loc[test, target], preds))\n",
    "    print(metrics.classification_report(kaggle_input.loc[test, target], preds))\n",
    "    print(metrics.confusion_matrix(kaggle_input.loc[test, target], preds))\n",
    "    print(nltk.Counter(kaggle_input.loc[test, target]))\n",
    "print('Mean: %s' % str(sum(sc_mean)/len(sc_mean)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch5\"></a>\n",
    "# 5. Cross-data validation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Pipeline([\n",
    "                ('selector', TextSelector(key='description')),\n",
    "                ('vectorizer', TfidfVectorizer(ngram_range=(1,1), stop_words=stop_words, analyzer='word', \n",
    "                                               norm='l2', tokenizer=LemmaTokenizer()))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('text', Pipeline(memory=None,\n",
       "     steps=[('selector', TextSelector(key='description')), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_featur...stimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('text', text),\n",
    "                 ('clf',RandomForestClassifier(random_state=42))\n",
    "                 ])\n",
    "    \n",
    "pipe.fit(kaggle_input[['description']], kaggle_input['grape_variety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725925925925926\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.71      0.95      0.81        91\n",
      "     pinot noir       0.64      0.92      0.76        59\n",
      "sauvignon blanc       0.89      0.54      0.67        76\n",
      "          syrah       0.79      0.34      0.48        44\n",
      "\n",
      "    avg / total       0.76      0.73      0.71       270\n",
      "\n",
      "[[86  1  4  0]\n",
      " [ 1 54  0  4]\n",
      " [32  3 41  0]\n",
      " [ 2 26  1 15]]\n",
      "Counter({'chardonnay': 91, 'sauvignon blanc': 76, 'pinot noir': 59, 'syrah': 44})\n"
     ]
    }
   ],
   "source": [
    "# test stats\n",
    "preds = pipe.predict(data_input[['description']])\n",
    "print(metrics.accuracy_score(data_input['grape_variety'], preds))\n",
    "print(metrics.classification_report(data_input['grape_variety'], preds))\n",
    "print(metrics.confusion_matrix(data_input['grape_variety'], preds))\n",
    "print(nltk.Counter(data_input['grape_variety']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_dummies = pd.get_dummies(kaggle_input['colour'])\n",
    "kaggle_input = kaggle_input.merge(colour_dummies, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "combined_features = ['description', 'white', 'red']\n",
    "target = 'grape_variety'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(kaggle_input[combined_features], kaggle_input[target], \n",
    "                                                    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = Pipeline([\n",
    "                ('selector', NumberSelector(key='red')),\n",
    "                ])\n",
    "white = Pipeline([\n",
    "                ('selector', NumberSelector(key='white')),\n",
    "                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Pipeline([\n",
    "                ('selector', TextSelector(key='description')),\n",
    "                ('vectorizer', TfidfVectorizer(ngram_range=(1,1), stop_words=stop_words, analyzer='word', \n",
    "                                               norm='l2', tokenizer=LemmaTokenizer()))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = FeatureUnion([('description', text),\n",
    "                      ('red', red),\n",
    "                      ('white', white)\n",
    "                      ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feats', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('description', Pipeline(steps=[('selector', TextSelector(key='description')), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',...stimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('feats', feats),\n",
    "                 ('clf',RandomForestClassifier(random_state=42))\n",
    "                 ])\n",
    "    \n",
    "pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866718695802983\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.85      0.98      0.91      3822\n",
      "     pinot noir       0.86      0.98      0.92      4378\n",
      "sauvignon blanc       0.92      0.59      0.72      1635\n",
      "          syrah       0.93      0.59      0.72      1697\n",
      "\n",
      "    avg / total       0.87      0.87      0.86     11532\n",
      "\n",
      "[[3735    1   86    0]\n",
      " [   4 4296    1   77]\n",
      " [ 669    0  966    0]\n",
      " [   1  698    0  998]]\n",
      "Counter({'pinot noir': 4378, 'chardonnay': 3822, 'syrah': 1697, 'sauvignon blanc': 1635})\n"
     ]
    }
   ],
   "source": [
    "# test stats\n",
    "preds = pipe.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, preds))\n",
    "print(metrics.classification_report(y_test, preds))\n",
    "print(metrics.confusion_matrix(y_test, preds))\n",
    "print(nltk.Counter(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8668440934065934\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.85      0.97      0.91      3914\n",
      "     pinot noir       0.87      0.98      0.92      4421\n",
      "sauvignon blanc       0.89      0.61      0.72      1655\n",
      "          syrah       0.90      0.60      0.72      1658\n",
      "\n",
      "    avg / total       0.87      0.87      0.86     11648\n",
      "\n",
      "[[3793    1  120    0]\n",
      " [   4 4312    1  104]\n",
      " [ 651    0 1004    0]\n",
      " [   2  668    0  988]]\n",
      "Counter({'pinot noir': 4421, 'chardonnay': 3914, 'syrah': 1658, 'sauvignon blanc': 1655})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8638392857142857\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.85      0.97      0.91      3914\n",
      "     pinot noir       0.86      0.98      0.92      4421\n",
      "sauvignon blanc       0.91      0.58      0.71      1655\n",
      "          syrah       0.90      0.59      0.71      1658\n",
      "\n",
      "    avg / total       0.87      0.86      0.85     11648\n",
      "\n",
      "[[3813    3   98    0]\n",
      " [   3 4312    0  106]\n",
      " [ 690    1  963    1]\n",
      " [   0  684    0  974]]\n",
      "Counter({'pinot noir': 4421, 'chardonnay': 3914, 'syrah': 1658, 'sauvignon blanc': 1655})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8676053919464239\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     chardonnay       0.84      0.97      0.90      3914\n",
      "     pinot noir       0.87      0.98      0.92      4421\n",
      "sauvignon blanc       0.90      0.58      0.71      1654\n",
      "          syrah       0.92      0.62      0.74      1658\n",
      "\n",
      "    avg / total       0.87      0.87      0.86     11647\n",
      "\n",
      "[[3803    4  107    0]\n",
      " [   7 4319    2   93]\n",
      " [ 691    1  962    0]\n",
      " [   5  630    2 1021]]\n",
      "Counter({'pinot noir': 4421, 'chardonnay': 3914, 'syrah': 1658, 'sauvignon blanc': 1654})\n",
      "Mean: 0.8660962570224343\n"
     ]
    }
   ],
   "source": [
    "### stratified training\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "sc_mean=[]\n",
    "for train, test in skf.split(kaggle_input[combined_features], kaggle_input[target]):\n",
    "    pipe.fit(kaggle_input.loc[train,combined_features], kaggle_input.loc[train, target])\n",
    "    preds = pipe.predict(kaggle_input.loc[test,combined_features])\n",
    "    sc_mean.append(metrics.accuracy_score(kaggle_input.loc[test, target], preds))\n",
    "    \n",
    "    print(metrics.accuracy_score(kaggle_input.loc[test, target], preds))\n",
    "    print(metrics.classification_report(kaggle_input.loc[test, target], preds))\n",
    "    print(metrics.confusion_matrix(kaggle_input.loc[test, target], preds))\n",
    "    print(nltk.Counter(kaggle_input.loc[test, target]))\n",
    "print('Mean: %s' % str(sum(sc_mean)/len(sc_mean)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch6\"></a>\n",
    "# 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not be impatient... Updates are coming soon to this page. In the meanwhile please feel free to contact me at [diveki@gmail.com](diveki@gmail.com). You can also fork this project from [my GitHub repository](https://github.com/diveki/WineSommelier) or you can take a sneaky look at [my GitHub Pages website](https://diveki.github.io).\n",
    "\n",
    "Just as a bonus, the prelude for this report can be found [here](https://diveki.github.io/projects/wine.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch7\"></a>\n",
    "# 7. References\n",
    "1. https://en.wikipedia.org/wiki/Sommelier\n",
    "2. Wine and Spirit Education Trust - https://www.wsetglobal.com/\n",
    "3. Wine terminology list - https://www.cawineclub.com/wine-tasting-terms\n",
    "4. Become a sommelier - https://diveki.github.io/projects/wine/wine.html\n",
    "5. Kagge Wine Review - https://www.kaggle.com/zynicide/wine-reviews\n",
    "6. Application of TfIdf-vectorizer on wine data - https://diveki.github.io/projects/wine/tfidf.html\n",
    "7. Lemmatization - https://en.wikipedia.org/wiki/Lemmatisation\n",
    "8. Label encoding - https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
